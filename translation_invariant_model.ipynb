{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"translation_invariant_model.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"2qxfjs69j9fZ","colab_type":"code","colab":{}},"source":["import numpy as np\n","import tables\n","import os\n","import pytz\n","from IPython.display import clear_output\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import time\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","import keras.backend as K\n","import datetime\n","import seaborn as sns\n","\n","sns.set(font_scale=1.5)\n","\n","# pd.set_option('display.max_rows', 30)\n","# pd.set_option('display.max_columns', 30)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"885eStuIj9fc","colab_type":"code","colab":{}},"source":["\n","class TranslationInvariant(BaseModel):\n","    \n","    def __init__(self):\n","\n","        super().__init__()\n","        \n","        # ========= Layer 1 =========\n","        self.lvl1_stride_x = 512\n","        self.lvl1_filter_height = 1\n","        self.lvl1_filter_width = 4096\n","\n","        self.lvl1_filters_amount= 512 # or so called out-channels\n","        self.lvl1_regions_x = (WINDOW_SIZE - self.lvl1_filter_width)/self.lvl1_stride_x + 1 # 25\n","        self.lvl1_regions_y = self.lvl1_filters_amount # 512\n","        # the shape of wsin and wcos is (1, 4096, 1, 512) for now\n","        self.wsin = np.empty((self.lvl1_filter_height, self.lvl1_filter_width, 1, self.lvl1_filters_amount), dtype=np.float32)\n","        self.wcos = np.empty((self.lvl1_filter_height, self.lvl1_filter_width, 1, self.lvl1_filters_amount), dtype=np.float32)\n","        \n","        self.frequencies = np.logspace(np.log(self.start_freq),\n","                                       np.log(self.end_freq),\n","                                       self.lvl1_filters_amount,\n","                                       base=np.e,\n","                                       endpoint=True)\n","        \n","        self.discrete_time = np.arange(self.lvl1_filter_width)\n","        self.create_filters()\n","        self.wsin_var = tf.constant(value=self.wsin, dtype='float32', name=\"wsin\")\n","        self.wcos_var = tf.constant(value=self.wcos, dtype='float32', name=\"wcos\")\n","        print('wsin_var: {}'.format(self.wsin_var))\n","        print('wcos_var: {}'.format(self.wcos_var))\n","\n","        \n","        # ========= Layer 2 =========\n","        self.lvl2_stride_y = 2\n","        self.lvl2_filter_height = 128\n","        self.lvl2_filter_width = 1\n","        \n","        self.lvl2_filters_amount = 128\n","        self.lvl2_regions_x = (self.lvl1_regions_x - self.lvl2_filter_width)/1 + 1 # 25\n","        self.lvl2_regions_y = (self.lvl1_regions_y - self.lvl2_filter_height)/self.lvl2_stride_y + 1 # 193\n","        \n","        self.lvl2_filters =  tf.Variable(initial_value=tf.random_normal([int(self.lvl2_filter_height),\n","                                                                         int(self.lvl2_filter_width),\n","                                                                         1,\n","                                                                         int(self.lvl2_filters_amount)], seed=999) * self.wscale,\n","                                         dtype='float32',\n","                                         name=\"lvl2_filters\")\n","        print('lvl2_filters: {}'.format(self.lvl2_filters))\n","\n","        # ========= Layer 3 =========\n","        self.lvl3_filter_height = 1\n","        self.lvl3_filter_width = self.lvl2_regions_x\n","        \n","        self.lvl3_filters_amount = 256       \n","        self.lvl3_regions_x = (self.lvl2_regions_x - self.lvl3_filter_width)/1 + 1\n","        self.lvl3_regions_y = (self.lvl2_regions_y - self.lvl3_filter_height)/1 + 1\n","        \n","        self.lvl3_filters = tf.Variable(initial_value=tf.random_normal([int(self.lvl3_filter_height),\n","                                                                        int(self.lvl3_filter_width),\n","                                                                        int(self.lvl2_filters_amount),\n","                                                                        int(self.lvl3_filters_amount)], seed=999) * self.wscale,\n","                                        dtype='float32',\n","                                        name=\"lvl3_filters\")\n","        print('lvl3_filters: {}'.format(self.lvl3_filters))\n","        \n","            \n","\n","    def define_graph(self, activation=None):\n","\n","        conv_sin = tf.nn.conv2d(input=self.input_X_ph,\n","                                filter=self.wsin_var,\n","                                strides=[1, 1, self.lvl1_stride_x, 1],\n","                                padding=\"VALID\")\n","        conv_cos = tf.nn.conv2d(input=self.input_X_ph,\n","                                filter=self.wcos_var,\n","                                strides=[1, 1, self.lvl1_stride_x, 1],\n","                                padding=\"VALID\")\n","        \n","        batch_size_ph = tf.shape(self.input_X_ph)[0]\n","\n","        lvl1_conv = tf.square(conv_sin) + tf.square(conv_cos)\n","        lvl1_conv = tf.transpose(lvl1_conv, perm=[0, 3, 2, 1])\n","        print(\"lvl1_conv shape: {}\".format(lvl1_conv.get_shape())) # (?, 512, 25, 1)\n","        \n","        \n","        lvl2_conv = tf.nn.relu(tf.nn.conv2d(input=tf.log(lvl1_conv + 10e-12),\n","                                            filter=self.lvl2_filters,\n","                                            strides=[1, self.lvl2_stride_y, 1, 1],\n","                                            padding=\"VALID\"))\n","        print(\"lvl2_conv shape: {}\".format(lvl2_conv.get_shape())) # (?, 193, 25, 128)\n","        \n","        \n","        \n","        lvl3_conv = tf.nn.relu(tf.nn.conv2d(input=lvl2_conv,\n","                                            filter=self.lvl3_filters,\n","                                            strides=[1, 1, 1, 1],\n","                                            padding=\"VALID\"))\n","        print(\"lvl3_conv shape: {}\".format(lvl3_conv.get_shape())) # \n","        \n","        \n","        # Output tensor the same shape as inputs except the last dimension is of size units.\n","        dense_layer = tf.layers.Dense(units=MIDI_PITCH_AMOUNT, activation=activation)\n","        self.pred_y_ph = dense_layer(tf.reshape(lvl3_conv,\n","                                                shape=[batch_size_ph, tf.to_int32(self.lvl3_regions_x * self.lvl3_regions_y * self.lvl3_filters_amount)]))\n","        \n","        self.loss = tf.reduce_mean(tf.reduce_sum((self.input_y_ph - self.pred_y_ph) ** 2, axis=1)) \n","        y_pred_converted =  tf.cast(tf.math.round(self.pred_y_ph), tf.int32)\n","        \n","        \n","        self.optimizer_step = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.loss)\n","        \n","\n","\n"],"execution_count":0,"outputs":[]}]}